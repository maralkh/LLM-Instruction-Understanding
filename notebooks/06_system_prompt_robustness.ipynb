{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6: System Prompt Robustness\n",
    "\n",
    "**Goal:** Test how robust system prompt effects are to paraphrasing and variations.\n",
    "\n",
    "**Setup:**\n",
    "- Fixed test prompts\n",
    "- Same system prompt intent expressed differently\n",
    "- Measure consistency of effects across paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.model_utils import load_model\n",
    "from src.metrics import DistributionMetrics\n",
    "from src.visualization import set_style\n",
    "from src.test_configs import ALL_TEST_PROMPTS, build_chat_prompt\n",
    "\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Paraphrase Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same intent, different wording\n",
    "PARAPHRASE_SETS = {\n",
    "    \"be_concise\": [\n",
    "        \"Be concise.\",\n",
    "        \"Keep it brief.\",\n",
    "        \"Short answers only.\",\n",
    "        \"Be as brief as possible.\",\n",
    "        \"Respond concisely.\",\n",
    "        \"Use few words.\",\n",
    "        \"Keep responses short.\",\n",
    "    ],\n",
    "    \n",
    "    \"be_helpful\": [\n",
    "        \"Be helpful.\",\n",
    "        \"Help the user.\",\n",
    "        \"Provide helpful responses.\",\n",
    "        \"Be as helpful as possible.\",\n",
    "        \"Assist the user effectively.\",\n",
    "        \"Give useful answers.\",\n",
    "        \"Be a helpful assistant.\",\n",
    "    ],\n",
    "    \n",
    "    \"be_accurate\": [\n",
    "        \"Be accurate.\",\n",
    "        \"Ensure accuracy.\",\n",
    "        \"Provide accurate information.\",\n",
    "        \"Be precise and correct.\",\n",
    "        \"Give accurate answers.\",\n",
    "        \"Accuracy is paramount.\",\n",
    "        \"Make sure your answers are correct.\",\n",
    "    ],\n",
    "    \n",
    "    \"think_step_by_step\": [\n",
    "        \"Think step by step.\",\n",
    "        \"Reason through this step by step.\",\n",
    "        \"Work through this systematically.\",\n",
    "        \"Break this down into steps.\",\n",
    "        \"Analyze this step by step.\",\n",
    "        \"Take it one step at a time.\",\n",
    "        \"Proceed methodically.\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure Paraphrase Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SUBSET = ALL_TEST_PROMPTS[:8]\n",
    "\n",
    "def measure_paraphrase_consistency(model, test_prompts, paraphrase_sets):\n",
    "    results = []\n",
    "    \n",
    "    for intent, paraphrases in tqdm(paraphrase_sets.items()):\n",
    "        for test in test_prompts:\n",
    "            # Get distribution for each paraphrase\n",
    "            distributions = []\n",
    "            for para in paraphrases:\n",
    "                prompt = build_chat_prompt(para, test[\"prompt\"], model.tokenizer)\n",
    "                dist = model.get_next_token_distribution(prompt, top_k=50)\n",
    "                distributions.append({\n",
    "                    \"paraphrase\": para,\n",
    "                    \"full_probs\": dist[\"full_probs\"],\n",
    "                    \"entropy\": dist[\"entropy\"],\n",
    "                    \"top_token\": dist[\"top_tokens\"][0]\n",
    "                })\n",
    "            \n",
    "            # Calculate pairwise JS divergences\n",
    "            js_values = []\n",
    "            for i in range(len(distributions)):\n",
    "                for j in range(i+1, len(distributions)):\n",
    "                    js = DistributionMetrics.jensen_shannon(\n",
    "                        distributions[i][\"full_probs\"],\n",
    "                        distributions[j][\"full_probs\"]\n",
    "                    )\n",
    "                    js_values.append(js)\n",
    "            \n",
    "            # Check top token consistency\n",
    "            top_tokens = [d[\"top_token\"] for d in distributions]\n",
    "            top_token_consistency = len(set(top_tokens)) == 1\n",
    "            \n",
    "            results.append({\n",
    "                \"intent\": intent,\n",
    "                \"test_id\": test[\"id\"],\n",
    "                \"category\": test[\"category\"],\n",
    "                \"mean_js\": np.mean(js_values),\n",
    "                \"max_js\": np.max(js_values),\n",
    "                \"entropy_std\": np.std([d[\"entropy\"] for d in distributions]),\n",
    "                \"top_token_consistent\": top_token_consistency,\n",
    "                \"n_unique_top_tokens\": len(set(top_tokens))\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "consistency_df = measure_paraphrase_consistency(model, TEST_SUBSET, PARAPHRASE_SETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency by intent\n",
    "intent_consistency = consistency_df.groupby('intent').agg({\n",
    "    'mean_js': ['mean', 'std'],\n",
    "    'top_token_consistent': 'mean',\n",
    "    'n_unique_top_tokens': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "intent_consistency.columns = ['js_mean', 'js_std', 'token_consistency', 'n_unique_tokens']\n",
    "intent_consistency = intent_consistency.sort_values('js_mean')\n",
    "\n",
    "print(\"=== Paraphrase Robustness by Intent ===\")\n",
    "print(\"Lower JS = more robust to paraphrasing\")\n",
    "print(intent_consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# JS divergence between paraphrases\n",
    "ax = axes[0]\n",
    "data = intent_consistency['js_mean']\n",
    "colors = plt.cm.RdYlGn_r(data / data.max())\n",
    "ax.barh(range(len(data)), data.values, xerr=intent_consistency['js_std'], color=colors, capsize=3)\n",
    "ax.set_yticks(range(len(data)))\n",
    "ax.set_yticklabels(data.index)\n",
    "ax.set_xlabel('Mean JS Divergence Between Paraphrases')\n",
    "ax.set_title('Paraphrase Sensitivity\\n(Lower = More Robust)')\n",
    "\n",
    "# Top token consistency\n",
    "ax = axes[1]\n",
    "data = intent_consistency['token_consistency'] * 100\n",
    "ax.barh(range(len(data)), data.values, alpha=0.7)\n",
    "ax.set_yticks(range(len(data)))\n",
    "ax.set_yticklabels(data.index)\n",
    "ax.set_xlabel('% Prompts with Consistent Top Token')\n",
    "ax.set_title('Top Token Consistency Across Paraphrases')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/exp6_robustness.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Sensitive Paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each intent, find which paraphrases cause most divergence\n",
    "print(\"=== Most Divergent Paraphrase Pairs ===\")\n",
    "\n",
    "for intent, paraphrases in PARAPHRASE_SETS.items():\n",
    "    # Sample one test\n",
    "    test = TEST_SUBSET[0]\n",
    "    \n",
    "    # Get all distributions\n",
    "    dists = []\n",
    "    for para in paraphrases:\n",
    "        prompt = build_chat_prompt(para, test[\"prompt\"], model.tokenizer)\n",
    "        dist = model.get_next_token_distribution(prompt, top_k=50)\n",
    "        dists.append((para, dist[\"full_probs\"]))\n",
    "    \n",
    "    # Find max divergent pair\n",
    "    max_js = 0\n",
    "    max_pair = None\n",
    "    for i in range(len(dists)):\n",
    "        for j in range(i+1, len(dists)):\n",
    "            js = DistributionMetrics.jensen_shannon(dists[i][1], dists[j][1])\n",
    "            if js > max_js:\n",
    "                max_js = js\n",
    "                max_pair = (dists[i][0], dists[j][0])\n",
    "    \n",
    "    print(f\"\\n{intent}:\")\n",
    "    print(f\"  Max JS: {max_js:.4f}\")\n",
    "    if max_pair:\n",
    "        print(f\"  '{max_pair[0]}' vs '{max_pair[1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Summary ===\")\n",
    "most_robust = intent_consistency['js_mean'].idxmin()\n",
    "least_robust = intent_consistency['js_mean'].idxmax()\n",
    "print(f\"Most robust intent: {most_robust}\")\n",
    "print(f\"Least robust intent: {least_robust}\")\n",
    "print(f\"\\nImplication: '{least_robust}' instructions are sensitive to exact wording\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../results/exp6_results.json', 'w') as f:\n",
    "    json.dump({\"intent_consistency\": intent_consistency.to_dict()}, f, indent=2, default=float)\n",
    "print(\"Saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
