{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Distribution Shift Under Different System Prompts\n",
    "\n",
    "**Goal:** Measure how different system prompts change the output distribution for the SAME user queries.\n",
    "\n",
    "**Setup:**\n",
    "- Fixed test prompts (30 prompts across 6 categories)\n",
    "- Variable: 16 different system prompts\n",
    "- Metrics: KL divergence, JS divergence, entropy, top-k overlap\n",
    "\n",
    "**Key Questions:**\n",
    "- Which system prompts cause the largest distribution shifts?\n",
    "- Are some prompt categories more sensitive to system prompts?\n",
    "- Do certain system prompts cluster together in their effects?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab setup\n",
    "try:\n",
    "    import google.colab\n",
    "    import os\n",
    "\n",
    "    # Clone repo if not already there\n",
    "    if not os.path.exists('LLM-Instruction-Understanding'):\n",
    "        !git clone https://github.com/maralkh/LLM-Instruction-Understanding.git\n",
    "    \n",
    "    # Change directory\n",
    "    os.chdir('LLM-Instruction-Understanding')\n",
    "    \n",
    "    # Install requirements\n",
    "    !pip install -r requirements.txt\n",
    "    \n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.model_utils import load_model\n",
    "from src.metrics import DistributionMetrics\n",
    "from src.visualization import set_style\n",
    "from src.test_configs import (\n",
    "    TEST_PROMPTS, ALL_TEST_PROMPTS, SYSTEM_PROMPTS,\n",
    "    build_chat_prompt, get_all_categories\n",
    ")\n",
    "\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "print(f\"Testing {len(ALL_TEST_PROMPTS)} prompts × {len(SYSTEM_PROMPTS)} system prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collect Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_distributions(model, test_prompts, system_prompts):\n",
    "    results = []\n",
    "    total = len(test_prompts) * len(system_prompts)\n",
    "    pbar = tqdm(total=total, desc=\"Collecting distributions\")\n",
    "    \n",
    "    for test in test_prompts:\n",
    "        for sys_name, sys_info in system_prompts.items():\n",
    "            full_prompt = build_chat_prompt(sys_info[\"text\"], test[\"prompt\"], model.tokenizer)\n",
    "            dist = model.get_next_token_distribution(full_prompt, top_k=100)\n",
    "            \n",
    "            results.append({\n",
    "                \"test_id\": test[\"id\"],\n",
    "                \"test_prompt\": test[\"prompt\"],\n",
    "                \"category\": test[\"category\"],\n",
    "                \"system_prompt\": sys_name,\n",
    "                \"entropy\": dist[\"entropy\"],\n",
    "                \"top_token\": dist[\"top_tokens\"][0] if dist[\"top_tokens\"] else \"\",\n",
    "                \"top_prob\": dist[\"top_probs\"][0] if dist[\"top_probs\"] else 0,\n",
    "                \"top_5_tokens\": dist[\"top_tokens\"][:5],\n",
    "                \"full_probs\": dist[\"full_probs\"]\n",
    "            })\n",
    "            pbar.update(1)\n",
    "    pbar.close()\n",
    "    return results\n",
    "\n",
    "all_distributions = collect_distributions(model, ALL_TEST_PROMPTS, SYSTEM_PROMPTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Divergences from Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_divergences(distributions, baseline=\"none\"):\n",
    "    by_test = {}\n",
    "    for d in distributions:\n",
    "        if d[\"test_id\"] not in by_test:\n",
    "            by_test[d[\"test_id\"]] = {}\n",
    "        by_test[d[\"test_id\"]][d[\"system_prompt\"]] = d\n",
    "    \n",
    "    divergences = []\n",
    "    for test_id, sys_dists in by_test.items():\n",
    "        if baseline not in sys_dists:\n",
    "            continue\n",
    "        base = sys_dists[baseline]\n",
    "        \n",
    "        for sys_name, sys_dist in sys_dists.items():\n",
    "            if sys_name == baseline:\n",
    "                continue\n",
    "            \n",
    "            kl = DistributionMetrics.kl_divergence(base[\"full_probs\"], sys_dist[\"full_probs\"])\n",
    "            js = DistributionMetrics.jensen_shannon(base[\"full_probs\"], sys_dist[\"full_probs\"])\n",
    "            overlap = DistributionMetrics.top_k_overlap(base[\"top_5_tokens\"], sys_dist[\"top_5_tokens\"])\n",
    "            \n",
    "            divergences.append({\n",
    "                \"test_id\": test_id, \"category\": base[\"category\"], \"system_prompt\": sys_name,\n",
    "                \"kl_divergence\": kl, \"js_divergence\": js, \"top_5_overlap\": overlap,\n",
    "                \"entropy_change\": sys_dist[\"entropy\"] - base[\"entropy\"],\n",
    "                \"top_token_changed\": base[\"top_token\"] != sys_dist[\"top_token\"]\n",
    "            })\n",
    "    return pd.DataFrame(divergences)\n",
    "\n",
    "divergence_df = calculate_divergences(all_distributions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System Prompt Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_impact = divergence_df.groupby('system_prompt').agg({\n",
    "    'js_divergence': ['mean', 'std'],\n",
    "    'entropy_change': 'mean',\n",
    "    'top_token_changed': 'mean'\n",
    "}).round(4)\n",
    "sys_impact.columns = ['js_mean', 'js_std', 'entropy_change', 'top_change_rate']\n",
    "sys_impact = sys_impact.sort_values('js_mean', ascending=False)\n",
    "print(sys_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('./results', exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "s = sys_impact.sort_values('js_mean')\n",
    "axes[0].barh(range(len(s)), s['js_mean'], xerr=s['js_std'], capsize=3, alpha=0.7)\n",
    "axes[0].set_yticks(range(len(s))); axes[0].set_yticklabels(s.index)\n",
    "axes[0].set_xlabel('JS Divergence'); axes[0].set_title('Distribution Shift')\n",
    "\n",
    "colors = ['green' if x > 0 else 'red' for x in s['entropy_change']]\n",
    "axes[1].barh(range(len(s)), s['entropy_change'], color=colors, alpha=0.7)\n",
    "axes[1].set_yticks(range(len(s))); axes[1].set_yticklabels(s.index)\n",
    "axes[1].set_xlabel('Entropy Change'); axes[1].set_title('Uncertainty Change')\n",
    "\n",
    "axes[2].barh(range(len(s)), s['top_change_rate']*100, alpha=0.7)\n",
    "axes[2].set_yticks(range(len(s))); axes[2].set_yticklabels(s.index)\n",
    "axes[2].set_xlabel('% Changed'); axes[2].set_title('Top Token Change Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/exp1_system_prompt_impact.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Category Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = divergence_df.pivot_table(values='js_divergence', index='system_prompt', columns='category', aggfunc='mean')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax)\n",
    "ax.set_title('JS Divergence: System Prompt × Category')\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/exp1_heatmap.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "import json\n",
    "with open('./results/exp1_results.json', 'w') as f:\n",
    "    json.dump({\"system_impact\": sys_impact.to_dict(), \"pivot\": pivot.to_dict()}, f, indent=2, default=float)\n",
    "print(\"Saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
