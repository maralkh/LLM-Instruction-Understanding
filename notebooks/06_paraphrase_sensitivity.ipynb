{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6: Output Distribution Under Paraphrase\n",
    "\n",
    "**Goal:** Test whether semantically equivalent prompts produce equivalent outputs.\n",
    "\n",
    "**Key Questions:**\n",
    "- Do paraphrased prompts yield similar distributions?\n",
    "- Is the model responding to meaning or surface form?\n",
    "- Which paraphrases break prompt effectiveness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "\n",
    "from src.model_utils import load_model\n",
    "from src.metrics import DistributionMetrics, compute_all_metrics, ExperimentResults\n",
    "from src.visualization import set_style, plot_distribution_comparison\n",
    "\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Paraphrase Sets\n",
    "\n",
    "We create semantically equivalent prompts with different surface forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paraphrase sets - semantically equivalent prompts\n",
    "PARAPHRASE_SETS = {\n",
    "    \"chain_of_thought\": {\n",
    "        \"original\": \"Let's think step by step.\",\n",
    "        \"paraphrases\": [\n",
    "            \"Let's approach this systematically.\",\n",
    "            \"Let's work through this one step at a time.\",\n",
    "            \"Let's break this down into steps.\",\n",
    "            \"Let's solve this step-by-step.\",\n",
    "            \"Let's reason through this carefully.\",\n",
    "            \"Let's analyze this methodically.\",\n",
    "            \"Think about this step by step.\",\n",
    "            \"Work through this systematically.\",\n",
    "            \"Proceed step by step.\",\n",
    "            \"Take it one step at a time.\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"expert_persona\": {\n",
    "        \"original\": \"You are an expert.\",\n",
    "        \"paraphrases\": [\n",
    "            \"You are a specialist in this field.\",\n",
    "            \"You have extensive expertise.\",\n",
    "            \"You are highly knowledgeable.\",\n",
    "            \"You are a professional.\",\n",
    "            \"You are an authority on this topic.\",\n",
    "            \"You possess expert-level knowledge.\",\n",
    "            \"You are a subject matter expert.\",\n",
    "            \"Act as an expert.\",\n",
    "            \"Respond as an expert would.\",\n",
    "            \"Answer like an expert.\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"instruction\": {\n",
    "        \"original\": \"Answer the following question.\",\n",
    "        \"paraphrases\": [\n",
    "            \"Please answer this question.\",\n",
    "            \"Respond to the question below.\",\n",
    "            \"Provide an answer to this question.\",\n",
    "            \"Give your answer to the following.\",\n",
    "            \"Answer this:\",\n",
    "            \"What is your answer to this question?\",\n",
    "            \"Please respond to the following question.\",\n",
    "            \"Here is a question to answer.\",\n",
    "            \"Question for you to answer:\",\n",
    "            \"Consider and answer this question.\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"be_careful\": {\n",
    "        \"original\": \"Be careful and accurate.\",\n",
    "        \"paraphrases\": [\n",
    "            \"Take care to be precise.\",\n",
    "            \"Ensure accuracy in your response.\",\n",
    "            \"Be thorough and correct.\",\n",
    "            \"Pay attention to accuracy.\",\n",
    "            \"Make sure your answer is accurate.\",\n",
    "            \"Respond with care and precision.\",\n",
    "            \"Be meticulous in your answer.\",\n",
    "            \"Carefully consider your response.\",\n",
    "            \"Accuracy is important here.\",\n",
    "            \"Please be precise.\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test questions\n",
    "TEST_QUESTIONS = [\n",
    "    {\"q\": \"What is 127 + 385?\", \"a\": \"512\"},\n",
    "    {\"q\": \"What is the capital of Australia?\", \"a\": \"Canberra\"},\n",
    "    {\"q\": \"What is the chemical symbol for gold?\", \"a\": \"Au\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure Paraphrase Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_paraphrase_consistency(model, paraphrase_set, question, expected):\n",
    "    \"\"\"\n",
    "    Test how consistent model behavior is across paraphrased prompts.\n",
    "    \"\"\"\n",
    "    original = paraphrase_set[\"original\"]\n",
    "    paraphrases = paraphrase_set[\"paraphrases\"]\n",
    "    \n",
    "    # Build prompts\n",
    "    original_prompt = f\"{original}\\n\\n{question}\"\n",
    "    \n",
    "    # Get original distribution\n",
    "    orig_dist = model.get_next_token_distribution(original_prompt)\n",
    "    orig_probs = model.get_sequence_log_probs(original_prompt, \" \" + expected)\n",
    "    \n",
    "    results = [{\n",
    "        \"variant\": \"original\",\n",
    "        \"text\": original,\n",
    "        \"target_log_prob\": orig_probs[\"total_log_prob\"],\n",
    "        \"entropy\": orig_dist[\"entropy\"],\n",
    "        \"top_5\": orig_dist[\"top_tokens\"][:5],\n",
    "        \"kl_from_original\": 0.0,\n",
    "        \"js_from_original\": 0.0\n",
    "    }]\n",
    "    \n",
    "    orig_full_probs = orig_dist[\"full_probs\"]\n",
    "    \n",
    "    # Test each paraphrase\n",
    "    for para in paraphrases:\n",
    "        para_prompt = f\"{para}\\n\\n{question}\"\n",
    "        para_dist = model.get_next_token_distribution(para_prompt)\n",
    "        para_probs = model.get_sequence_log_probs(para_prompt, \" \" + expected)\n",
    "        para_full_probs = para_dist[\"full_probs\"]\n",
    "        \n",
    "        # Calculate divergence from original\n",
    "        kl = DistributionMetrics.kl_divergence(orig_full_probs, para_full_probs)\n",
    "        js = DistributionMetrics.jensen_shannon(orig_full_probs, para_full_probs)\n",
    "        \n",
    "        results.append({\n",
    "            \"variant\": \"paraphrase\",\n",
    "            \"text\": para,\n",
    "            \"target_log_prob\": para_probs[\"total_log_prob\"],\n",
    "            \"entropy\": para_dist[\"entropy\"],\n",
    "            \"top_5\": para_dist[\"top_tokens\"][:5],\n",
    "            \"kl_from_original\": kl,\n",
    "            \"js_from_original\": js\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run paraphrase analysis\n",
    "all_paraphrase_results = {}\n",
    "\n",
    "for set_name, paraphrase_set in PARAPHRASE_SETS.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing: {set_name}\")\n",
    "    print(f\"Original: '{paraphrase_set['original']}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    set_results = []\n",
    "    \n",
    "    for test in TEST_QUESTIONS:\n",
    "        results = test_paraphrase_consistency(\n",
    "            model, paraphrase_set, test[\"q\"], test[\"a\"]\n",
    "        )\n",
    "        for r in results:\n",
    "            r[\"question\"] = test[\"q\"]\n",
    "        set_results.extend(results)\n",
    "    \n",
    "    all_paraphrase_results[set_name] = set_results\n",
    "    \n",
    "    # Summary stats\n",
    "    paraphrase_only = [r for r in set_results if r[\"variant\"] == \"paraphrase\"]\n",
    "    kl_values = [r[\"kl_from_original\"] for r in paraphrase_only]\n",
    "    js_values = [r[\"js_from_original\"] for r in paraphrase_only]\n",
    "    log_prob_values = [r[\"target_log_prob\"] for r in paraphrase_only]\n",
    "    orig_log_probs = [r[\"target_log_prob\"] for r in set_results if r[\"variant\"] == \"original\"]\n",
    "    \n",
    "    print(f\"\\nDistribution divergence from original:\")\n",
    "    print(f\"  KL: mean={np.mean(kl_values):.4f}, std={np.std(kl_values):.4f}\")\n",
    "    print(f\"  JS: mean={np.mean(js_values):.4f}, std={np.std(js_values):.4f}\")\n",
    "    print(f\"\\nTarget log-prob:\")\n",
    "    print(f\"  Original: {np.mean(orig_log_probs):.4f}\")\n",
    "    print(f\"  Paraphrases: mean={np.mean(log_prob_values):.4f}, std={np.std(log_prob_values):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Identify Breaking Paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find paraphrases that significantly hurt performance\n",
    "print(\"=== Paraphrases That Break Performance ===\")\n",
    "\n",
    "for set_name, results in all_paraphrase_results.items():\n",
    "    print(f\"\\n{set_name}:\")\n",
    "    \n",
    "    # Get original performance per question\n",
    "    orig_by_q = {r[\"question\"]: r[\"target_log_prob\"] \n",
    "                 for r in results if r[\"variant\"] == \"original\"}\n",
    "    \n",
    "    # Find worst performing paraphrases\n",
    "    para_results = [r for r in results if r[\"variant\"] == \"paraphrase\"]\n",
    "    \n",
    "    for r in para_results:\n",
    "        orig_prob = orig_by_q[r[\"question\"]]\n",
    "        r[\"relative_change\"] = r[\"target_log_prob\"] - orig_prob\n",
    "    \n",
    "    # Group by paraphrase text and average\n",
    "    para_performance = {}\n",
    "    for r in para_results:\n",
    "        text = r[\"text\"]\n",
    "        if text not in para_performance:\n",
    "            para_performance[text] = []\n",
    "        para_performance[text].append(r[\"relative_change\"])\n",
    "    \n",
    "    avg_performance = {t: np.mean(v) for t, v in para_performance.items()}\n",
    "    sorted_paras = sorted(avg_performance.items(), key=lambda x: x[1])\n",
    "    \n",
    "    print(\"  Worst paraphrases (hurt most):\")\n",
    "    for text, change in sorted_paras[:3]:\n",
    "        print(f\"    '{text[:50]}...': {change:+.4f}\")\n",
    "    \n",
    "    print(\"  Best paraphrases (help most):\")\n",
    "    for text, change in sorted_paras[-3:]:\n",
    "        print(f\"    '{text[:50]}...': {change:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Surface Form Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_surface_features(text):\n",
    "    \"\"\"Extract surface-level features from prompt text.\"\"\"\n",
    "    return {\n",
    "        \"length\": len(text),\n",
    "        \"word_count\": len(text.split()),\n",
    "        \"starts_with_lets\": text.lower().startswith(\"let's\"),\n",
    "        \"starts_with_you\": text.lower().startswith(\"you\"),\n",
    "        \"has_period\": \".\" in text,\n",
    "        \"has_colon\": \":\" in text,\n",
    "        \"imperative\": text.split()[0].lower() in [\"be\", \"think\", \"answer\", \"respond\", \"provide\", \"give\", \"work\", \"take\", \"proceed\"],\n",
    "        \"has_please\": \"please\" in text.lower(),\n",
    "        \"ends_period\": text.strip().endswith(\".\"),\n",
    "        \"ends_colon\": text.strip().endswith(\":\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which surface features correlate with performance\n",
    "all_features = []\n",
    "\n",
    "for set_name, results in all_paraphrase_results.items():\n",
    "    for r in results:\n",
    "        features = extract_surface_features(r[\"text\"])\n",
    "        features[\"target_log_prob\"] = r[\"target_log_prob\"]\n",
    "        features[\"set_name\"] = set_name\n",
    "        all_features.append(features)\n",
    "\n",
    "feature_df = pd.DataFrame(all_features)\n",
    "\n",
    "# Calculate correlations\n",
    "print(\"=== Surface Feature Correlations with Performance ===\")\n",
    "numeric_cols = [c for c in feature_df.columns if c not in ['target_log_prob', 'set_name']]\n",
    "\n",
    "correlations = []\n",
    "for col in numeric_cols:\n",
    "    corr = feature_df[col].astype(float).corr(feature_df['target_log_prob'])\n",
    "    if not np.isnan(corr):\n",
    "        correlations.append((col, corr))\n",
    "\n",
    "correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "for feat, corr in correlations:\n",
    "    print(f\"  {feat:20s}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Similarity vs Distribution Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lexical_overlap(text1, text2):\n",
    "    \"\"\"Simple lexical overlap as proxy for surface similarity.\"\"\"\n",
    "    words1 = set(text1.lower().split())\n",
    "    words2 = set(text2.lower().split())\n",
    "    \n",
    "    if not words1 or not words2:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection = words1 & words2\n",
    "    union = words1 | words2\n",
    "    \n",
    "    return len(intersection) / len(union)  # Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between lexical overlap and distribution similarity\n",
    "overlap_vs_divergence = []\n",
    "\n",
    "for set_name, results in all_paraphrase_results.items():\n",
    "    original_text = PARAPHRASE_SETS[set_name][\"original\"]\n",
    "    \n",
    "    for r in results:\n",
    "        if r[\"variant\"] == \"paraphrase\":\n",
    "            overlap = calculate_lexical_overlap(original_text, r[\"text\"])\n",
    "            overlap_vs_divergence.append({\n",
    "                \"set\": set_name,\n",
    "                \"lexical_overlap\": overlap,\n",
    "                \"kl_divergence\": r[\"kl_from_original\"],\n",
    "                \"js_divergence\": r[\"js_from_original\"],\n",
    "                \"text\": r[\"text\"]\n",
    "            })\n",
    "\n",
    "overlap_df = pd.DataFrame(overlap_vs_divergence)\n",
    "\n",
    "# Correlation\n",
    "corr_kl = overlap_df[\"lexical_overlap\"].corr(overlap_df[\"kl_divergence\"])\n",
    "corr_js = overlap_df[\"lexical_overlap\"].corr(overlap_df[\"js_divergence\"])\n",
    "\n",
    "print(f\"Correlation between lexical overlap and distribution divergence:\")\n",
    "print(f\"  Lexical overlap vs KL: {corr_kl:.4f}\")\n",
    "print(f\"  Lexical overlap vs JS: {corr_js:.4f}\")\n",
    "print(f\"\\nInterpretation: {'Surface form matters!' if abs(corr_kl) > 0.3 else 'Meaning matters more than form.'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter: lexical overlap vs KL\n",
    "for set_name in PARAPHRASE_SETS.keys():\n",
    "    subset = overlap_df[overlap_df[\"set\"] == set_name]\n",
    "    axes[0].scatter(subset[\"lexical_overlap\"], subset[\"kl_divergence\"], \n",
    "                    label=set_name, alpha=0.7, s=50)\n",
    "\n",
    "axes[0].set_xlabel(\"Lexical Overlap (Jaccard)\")\n",
    "axes[0].set_ylabel(\"KL Divergence from Original\")\n",
    "axes[0].set_title(\"Does Surface Similarity Predict Distribution Similarity?\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Box plot: divergence by paraphrase set\n",
    "data_for_box = [overlap_df[overlap_df[\"set\"] == s][\"js_divergence\"].values \n",
    "                for s in PARAPHRASE_SETS.keys()]\n",
    "bp = axes[1].boxplot(data_for_box, labels=list(PARAPHRASE_SETS.keys()), patch_artist=True)\n",
    "axes[1].set_ylabel(\"JS Divergence from Original\")\n",
    "axes[1].set_title(\"Distribution Sensitivity by Prompt Type\")\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/exp6_paraphrase_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 6 SUMMARY: Paraphrase Sensitivity\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Distribution Consistency Across Paraphrases:\")\n",
    "for set_name, results in all_paraphrase_results.items():\n",
    "    para_only = [r for r in results if r[\"variant\"] == \"paraphrase\"]\n",
    "    js_values = [r[\"js_from_original\"] for r in para_only]\n",
    "    print(f\"   {set_name}: JS divergence = {np.mean(js_values):.4f} ± {np.std(js_values):.4f}\")\n",
    "\n",
    "print(f\"\\n2. Surface Form vs Meaning:\")\n",
    "print(f\"   Lexical overlap correlation with divergence: {corr_kl:.4f}\")\n",
    "if abs(corr_kl) > 0.3:\n",
    "    print(\"   → Model is sensitive to surface form, not just meaning\")\n",
    "else:\n",
    "    print(\"   → Model responds more to semantic content than surface form\")\n",
    "\n",
    "print(\"\\n3. Actionable Insights:\")\n",
    "print(\"   - [Fill after running: Which paraphrase patterns work best?]\")\n",
    "print(\"   - [Fill after running: What surface features matter?]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "save_data = {\n",
    "    \"divergence_by_set\": {\n",
    "        set_name: {\n",
    "            \"mean_js\": float(np.mean([r[\"js_from_original\"] for r in results if r[\"variant\"] == \"paraphrase\"])),\n",
    "            \"std_js\": float(np.std([r[\"js_from_original\"] for r in results if r[\"variant\"] == \"paraphrase\"]))\n",
    "        }\n",
    "        for set_name, results in all_paraphrase_results.items()\n",
    "    },\n",
    "    \"surface_correlations\": dict(correlations),\n",
    "    \"lexical_vs_distribution_corr\": float(corr_kl)\n",
    "}\n",
    "\n",
    "with open('../results/exp6_paraphrase_results.json', 'w') as f:\n",
    "    json.dump(save_data, f, indent=2)\n",
    "\n",
    "print(\"Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
