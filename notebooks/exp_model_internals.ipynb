{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Model Internals - Why Instructions Change Behavior\n",
    "\n",
    "**Goal:** Understand the internal mechanisms through which system prompts affect model outputs.\n",
    "\n",
    "**Analysis Focus:**\n",
    "- Hidden state changes across layers\n",
    "- Which layers are most affected by system prompts?\n",
    "- Correlation between internal changes and output changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.exists('/content/LLM-Instruction-Understanding'):\n",
    "        !git clone https://github.com/maralkh/LLM-Instruction-Understanding.git\n",
    "    os.chdir('/content/LLM-Instruction-Understanding')\n",
    "    !pip install -q -r requirements.txt\n",
    "    sys.path.insert(0, '/content/LLM-Instruction-Understanding')\n",
    "else:\n",
    "    sys.path.insert(0, os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.model_utils import load_model\n",
    "from src.test_configs import get_all_test_prompts, get_core_system_prompts, build_chat_prompt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "layer_info = model.get_layer_info()\n",
    "print(f\"Model: {layer_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare Internals Across System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = get_all_test_prompts()[:5]\n",
    "system_prompts = get_core_system_prompts()\n",
    "baseline_sys = system_prompts['none']\n",
    "\n",
    "internal_comparisons = []\n",
    "\n",
    "for test in tqdm(test_prompts, desc=\"Analyzing\"):\n",
    "    for sys_name, sys_info in system_prompts.items():\n",
    "        if sys_name == 'none':\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            prompt_base = build_chat_prompt(baseline_sys['text'], test['prompt'], model.tokenizer)\n",
    "            prompt_var = build_chat_prompt(sys_info['text'], test['prompt'], model.tokenizer)\n",
    "            \n",
    "            comparison = model.compare_internals(prompt_base, prompt_var)\n",
    "            \n",
    "            for layer, hs_diff in comparison['hidden_state_diff'].items():\n",
    "                internal_comparisons.append({\n",
    "                    'test_id': test['id'],\n",
    "                    'category': test['category'],\n",
    "                    'system_prompt': sys_name,\n",
    "                    'layer': layer,\n",
    "                    'hs_cosine_sim': hs_diff['cosine_sim'],\n",
    "                    'hs_l2_norm': hs_diff['l2_norm'],\n",
    "                    'logit_cosine_sim': comparison['logit_diff']['cosine_sim'],\n",
    "                    'top_token_same': comparison['logit_diff']['top_token_same']\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "internals_df = pd.DataFrame(internal_comparisons)\n",
    "print(f\"Collected {len(internals_df)} measurements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Layer Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_impact = internals_df.groupby('layer').agg({\n",
    "    'hs_cosine_sim': 'mean',\n",
    "    'hs_l2_norm': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"=== Layer Impact ===\")\n",
    "print(layer_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(layer_impact.index, layer_impact['hs_cosine_sim'], 'o-')\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('Cosine Similarity to Baseline')\n",
    "ax.set_title('Hidden State Similarity by Layer')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(layer_impact.index, layer_impact['hs_l2_norm'], 'o-', color='orange')\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('L2 Distance')\n",
    "ax.set_title('Hidden State L2 Distance by Layer')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/layer_impact.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System Prompt Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_impact = internals_df.groupby('system_prompt').agg({\n",
    "    'hs_cosine_sim': 'mean',\n",
    "    'logit_cosine_sim': 'mean',\n",
    "    'top_token_same': 'mean'\n",
    "}).round(4).sort_values('hs_cosine_sim')\n",
    "\n",
    "print(\"=== System Prompt Impact ===\")\n",
    "print(sys_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "pivot = internals_df.pivot_table(values='hs_cosine_sim', index='system_prompt', columns='layer', aggfunc='mean')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "sns.heatmap(1 - pivot, cmap='YlOrRd', ax=ax)\n",
    "ax.set_title('Hidden State Change by System Prompt Ã— Layer')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/internals_heatmap.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n=== KEY FINDINGS ===\")\n",
    "print(f\"Most affected layer: {layer_impact['hs_cosine_sim'].idxmin()}\")\n",
    "print(f\"Most impactful system prompt: {sys_impact['hs_cosine_sim'].idxmin()}\")\n",
    "print(f\"Least impactful system prompt: {sys_impact['hs_cosine_sim'].idxmax()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "with open('../results/internals_analysis.json', 'w') as f:\n",
    "    json.dump({'layer_impact': layer_impact.to_dict(), 'sys_impact': sys_impact.to_dict()}, f, indent=2, default=float)\n",
    "print(\"Saved.\")"
   ]
  }
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
