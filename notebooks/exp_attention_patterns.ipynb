{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Attention Pattern Analysis\n",
    "\n",
    "**Goal:** Understand WHERE the model looks under different system prompts.\n",
    "\n",
    "**Key Questions:**\n",
    "- How does attention to system prompt tokens change with different instructions?\n",
    "- Which attention heads are most sensitive to system prompts?\n",
    "- Does CoT instruction change attention patterns differently than persona instructions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Setup path\n",
    "if 'google.colab' in sys.modules:\n",
    "    if not os.path.exists('/content/LLM-Instruction-Understanding'):\n",
    "        !git clone https://github.com/maralkh/LLM-Instruction-Understanding.git\n",
    "    os.chdir('/content/LLM-Instruction-Understanding')\n",
    "    !pip install -q -r requirements.txt\n",
    "    if '/content/LLM-Instruction-Understanding' not in sys.path:\n",
    "        sys.path.insert(0, '/content/LLM-Instruction-Understanding')\n",
    "else:\n",
    "    parent = os.path.abspath('..')\n",
    "    if parent not in sys.path:\n",
    "        sys.path.insert(0, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.model_utils import load_model\n",
    "from src.test_configs import (\n",
    "    get_test_prompts, get_system_prompts, get_core_system_prompts,\n",
    "    build_chat_prompt, get_all_test_prompts\n",
    ")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "layer_info = model.get_layer_info()\n",
    "print(f\"Model: {layer_info['model_name']}\")\n",
    "print(f\"Layers: {layer_info['n_layers']}, Heads: {layer_info['n_heads']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compare Attention Patterns Across System Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Test attention extraction on one prompt\n",
    "test_prompt = \"What is 2+2?\"\n",
    "attn_data = model.get_attention_patterns(test_prompt, debug=True)\n",
    "\n",
    "print(\"\\n=== Attention Stats by Layer ===\")\n",
    "for layer, stats in attn_data['attention_stats'].items():\n",
    "    print(f\"Layer {layer}: shape={stats['shape']}, min={stats['min']:.6f}, max={stats['max']:.6f}, mean={stats['mean']:.6f}\")\n",
    "\n",
    "print(\"\\n=== Entropy by Layer ===\")\n",
    "for layer, ent in attn_data['attention_entropy'].items():\n",
    "    print(f\"Layer {layer}: entropy={ent:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test cases\n",
    "test_prompts = get_all_test_prompts()[:5]\n",
    "system_prompts = get_core_system_prompts()\n",
    "\n",
    "print(f\"Testing {len(test_prompts)} prompts × {len(system_prompts)} system prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_attention_for_prompt(model, user_prompt, system_prompt_text, tokenizer):\n",
    "    \"\"\"Analyze attention patterns for a prompt.\"\"\"\n",
    "    full_prompt = build_chat_prompt(system_prompt_text, user_prompt, tokenizer)\n",
    "    \n",
    "    # Get attention patterns\n",
    "    attn_data = model.get_attention_patterns(full_prompt, aggregate=\"last_token\")\n",
    "    \n",
    "    # Get token boundaries\n",
    "    tokens = attn_data['tokens']\n",
    "    \n",
    "    # Try to identify system prompt region\n",
    "    sys_tokens = model.tokenizer(system_prompt_text, return_tensors=\"pt\").input_ids.shape[1] if system_prompt_text else 0\n",
    "    \n",
    "    return {\n",
    "        'tokens': tokens,\n",
    "        'n_tokens': len(tokens),\n",
    "        'sys_token_count': sys_tokens,\n",
    "        'layer_attention': attn_data['layer_attention'],\n",
    "        'attention_entropy': attn_data['attention_entropy'],\n",
    "        'attention_stats': attn_data.get('attention_stats', {})\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect attention data\n",
    "attention_results = []\n",
    "\n",
    "for test in tqdm(test_prompts, desc=\"Test prompts\"):\n",
    "    for sys_name, sys_info in system_prompts.items():\n",
    "        try:\n",
    "            attn_data = analyze_attention_for_prompt(\n",
    "                model, \n",
    "                test['prompt'], \n",
    "                sys_info['text'],\n",
    "                model.tokenizer\n",
    "            )\n",
    "            \n",
    "            # Calculate summary metrics with NaN handling\n",
    "            mean_entropy_by_layer = {k: v for k, v in attn_data['attention_entropy'].items()}\n",
    "            entropy_values = [v for v in mean_entropy_by_layer.values() if np.isfinite(v)]\n",
    "            mean_entropy = np.mean(entropy_values) if entropy_values else 0.0\n",
    "            \n",
    "            attention_results.append({\n",
    "                'test_id': test['id'],\n",
    "                'category': test['category'],\n",
    "                'system_prompt': sys_name,\n",
    "                'n_tokens': attn_data['n_tokens'],\n",
    "                'sys_tokens': attn_data['sys_token_count'],\n",
    "                'mean_attn_entropy': mean_entropy,\n",
    "                'layer_entropy': mean_entropy_by_layer,\n",
    "                'layer_attention': attn_data['layer_attention']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {test['id']}/{sys_name}: {e}\")\n",
    "\n",
    "attn_df = pd.DataFrame(attention_results)\n",
    "print(f\"Collected {len(attn_df)} attention analyses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Attention Entropy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare attention entropy across system prompts\n",
    "entropy_by_sys = attn_df.groupby('system_prompt')['mean_attn_entropy'].agg(['mean', 'std']).round(4)\n",
    "entropy_by_sys = entropy_by_sys.sort_values('mean')\n",
    "\n",
    "print(\"=== Attention Entropy by System Prompt ===\")\n",
    "print(\"Lower entropy = more focused attention\")\n",
    "print(entropy_by_sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.barh(range(len(entropy_by_sys)), entropy_by_sys['mean'], \n",
    "        xerr=entropy_by_sys['std'], capsize=3, alpha=0.7)\n",
    "ax.set_yticks(range(len(entropy_by_sys)))\n",
    "ax.set_yticklabels(entropy_by_sys.index)\n",
    "ax.set_xlabel('Mean Attention Entropy')\n",
    "ax.set_title('Attention Focus by System Prompt\\n(Lower = More Focused)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/attention_entropy_by_system.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Layer-wise Attention Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer-wise entropy for different system prompts\n",
    "def get_layer_entropy_matrix(attn_df, n_layers):\n",
    "    \"\"\"Create matrix of entropy by (system_prompt, layer).\"\"\"\n",
    "    systems = attn_df['system_prompt'].unique()\n",
    "    matrix = np.zeros((len(systems), n_layers))\n",
    "    counts = np.zeros((len(systems), n_layers))\n",
    "    \n",
    "    for i, sys in enumerate(systems):\n",
    "        sys_data = attn_df[attn_df['system_prompt'] == sys]\n",
    "        for row in sys_data['layer_entropy']:\n",
    "            for layer, entropy in row.items():\n",
    "                if layer < n_layers and np.isfinite(entropy):\n",
    "                    matrix[i, layer] += entropy\n",
    "                    counts[i, layer] += 1\n",
    "        # Avoid division by zero\n",
    "        counts[i, :] = np.maximum(counts[i, :], 1)\n",
    "        matrix[i, :] /= counts[i, :]\n",
    "    \n",
    "    return matrix, systems\n",
    "\n",
    "n_layers = layer_info['n_layers']\n",
    "entropy_matrix, sys_names = get_layer_entropy_matrix(attn_df, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of layer-wise entropy\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(entropy_matrix, \n",
    "            xticklabels=[f\"L{i}\" for i in range(n_layers)],\n",
    "            yticklabels=sys_names,\n",
    "            cmap='viridis', ax=ax, annot=False)\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('System Prompt')\n",
    "ax.set_title('Attention Entropy by Layer × System Prompt')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/attention_layer_heatmap.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Head-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze individual attention heads\n",
    "test_prompt = test_prompts[0]\n",
    "\n",
    "head_analyses = {}\n",
    "for sys_name, sys_info in list(system_prompts.items())[:4]:  # Just a few for visualization\n",
    "    full_prompt = build_chat_prompt(sys_info['text'], test_prompt['prompt'], model.tokenizer)\n",
    "    head_data = model.get_head_contributions(full_prompt)\n",
    "    head_analyses[sys_name] = head_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare head entropy across system prompts\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for ax, (sys_name, head_data) in zip(axes.flatten(), head_analyses.items()):\n",
    "    # Extract entropy for each head across layers\n",
    "    layers = sorted(head_data.keys())\n",
    "    n_heads = len(head_data[layers[0]])\n",
    "    \n",
    "    entropy_matrix = np.zeros((len(layers), n_heads))\n",
    "    for i, layer in enumerate(layers):\n",
    "        for head_info in head_data[layer]:\n",
    "            entropy_matrix[i, head_info['head']] = head_info['entropy']\n",
    "    \n",
    "    im = ax.imshow(entropy_matrix, aspect='auto', cmap='viridis')\n",
    "    ax.set_xlabel('Head')\n",
    "    ax.set_ylabel('Layer')\n",
    "    ax.set_title(f'{sys_name}')\n",
    "    plt.colorbar(im, ax=ax, label='Entropy')\n",
    "\n",
    "plt.suptitle('Head Entropy by Layer (per System Prompt)', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/head_entropy_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ATTENTION PATTERN ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. System prompts that focus attention most:\")\n",
    "for sys in entropy_by_sys.head(3).index:\n",
    "    print(f\"   • {sys}: entropy={entropy_by_sys.loc[sys, 'mean']:.4f}\")\n",
    "\n",
    "print(\"\\n2. System prompts with most distributed attention:\")\n",
    "for sys in entropy_by_sys.tail(3).index:\n",
    "    print(f\"   • {sys}: entropy={entropy_by_sys.loc[sys, 'mean']:.4f}\")\n",
    "\n",
    "print(\"\\n3. Implication:\")\n",
    "print(\"   - Focused attention may indicate clearer instruction interpretation\")\n",
    "print(\"   - CoT prompts may distribute attention more broadly for reasoning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "results = {\n",
    "    'entropy_by_system': entropy_by_sys.to_dict(),\n",
    "    'n_samples': len(attn_df),\n",
    "    'model': layer_info\n",
    "}\n",
    "\n",
    "with open('../results/attention_analysis.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=float)\n",
    "print(\"Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
