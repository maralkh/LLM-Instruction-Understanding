{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 9: Prompt-Task Interaction Matrix\n",
    "\n",
    "**Goal:** Understand whether prompt strategies are task-specific or general.\n",
    "\n",
    "**Key Questions:**\n",
    "- Do some strategies work universally across tasks?\n",
    "- Are there task-specific strategies?\n",
    "- Can certain strategies hurt performance on some tasks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.model_utils import load_model\n",
    "from src.visualization import set_style\n",
    "\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Task Types and Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = {\n",
    "    \"arithmetic\": [\n",
    "        {\"q\": \"What is 23 + 45?\", \"a\": \"68\"},\n",
    "        {\"q\": \"What is 156 - 89?\", \"a\": \"67\"},\n",
    "        {\"q\": \"What is 12 * 7?\", \"a\": \"84\"},\n",
    "    ],\n",
    "    \"factual\": [\n",
    "        {\"q\": \"What is the capital of France?\", \"a\": \"Paris\"},\n",
    "        {\"q\": \"What planet is known as the Red Planet?\", \"a\": \"Mars\"},\n",
    "        {\"q\": \"What is the chemical symbol for water?\", \"a\": \"H2O\"},\n",
    "    ],\n",
    "    \"reasoning\": [\n",
    "        {\"q\": \"If all cats are animals, and all animals need food, do cats need food?\", \"a\": \"yes\"},\n",
    "        {\"q\": \"John is taller than Mary. Mary is taller than Sue. Is John taller than Sue?\", \"a\": \"yes\"},\n",
    "        {\"q\": \"If it's raining, the ground is wet. The ground is wet. Is it definitely raining?\", \"a\": \"no\"},\n",
    "    ],\n",
    "    \"classification\": [\n",
    "        {\"q\": \"Is 'happy' a positive or negative word?\", \"a\": \"positive\"},\n",
    "        {\"q\": \"Is 'terrible' a positive or negative word?\", \"a\": \"negative\"},\n",
    "        {\"q\": \"Is 'excellent' a positive or negative word?\", \"a\": \"positive\"},\n",
    "    ],\n",
    "    \"extraction\": [\n",
    "        {\"q\": \"Extract the name: 'John Smith is a doctor.'\", \"a\": \"John Smith\"},\n",
    "        {\"q\": \"Extract the number: 'The price is $45.'\", \"a\": \"45\"},\n",
    "        {\"q\": \"Extract the city: 'She lives in Tokyo.'\", \"a\": \"Tokyo\"},\n",
    "    ],\n",
    "    \"completion\": [\n",
    "        {\"q\": \"Complete: The early bird catches the\", \"a\": \"worm\"},\n",
    "        {\"q\": \"Complete: An apple a day keeps the doctor\", \"a\": \"away\"},\n",
    "        {\"q\": \"Complete: Rome wasn't built in a\", \"a\": \"day\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "STRATEGIES = {\n",
    "    \"plain\": \"{question}\",\n",
    "    \"cot\": \"{question}\\n\\nLet's think step by step.\",\n",
    "    \"expert\": \"You are an expert. {question}\",\n",
    "    \"careful\": \"Be careful and accurate. {question}\",\n",
    "    \"structured\": \"Question: {question}\\nAnswer:\",\n",
    "    \"teacher\": \"You are a helpful teacher. {question}\",\n",
    "    \"concise\": \"{question} Answer concisely:\",\n",
    "    \"confident\": \"{question} I'm sure the answer is\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Interaction Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_strategy_on_task(model, strategy_template, task_questions):\n",
    "    log_probs = []\n",
    "    for item in task_questions:\n",
    "        prompt = strategy_template.format(question=item[\"q\"])\n",
    "        seq_probs = model.get_sequence_log_probs(prompt, \" \" + item[\"a\"])\n",
    "        log_probs.append(seq_probs[\"total_log_prob\"])\n",
    "    return {\"mean\": np.mean(log_probs), \"std\": np.std(log_probs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_matrix = []\n",
    "pbar = tqdm(total=len(STRATEGIES) * len(TASKS), desc=\"Building matrix\")\n",
    "\n",
    "for strategy_name, template in STRATEGIES.items():\n",
    "    for task_name, questions in TASKS.items():\n",
    "        result = evaluate_strategy_on_task(model, template, questions)\n",
    "        results_matrix.append({\n",
    "            \"strategy\": strategy_name,\n",
    "            \"task\": task_name,\n",
    "            \"mean_log_prob\": result[\"mean\"],\n",
    "            \"std_log_prob\": result[\"std\"]\n",
    "        })\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "matrix_df = pd.DataFrame(results_matrix)\n",
    "pivot_matrix = matrix_df.pivot(index='strategy', columns='task', values='mean_log_prob')\n",
    "print(pivot_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Absolute performance\n",
    "sns.heatmap(pivot_matrix, annot=True, fmt='.2f', cmap='RdYlGn', ax=axes[0],\n",
    "            cbar_kws={'label': 'Log Probability'})\n",
    "axes[0].set_title('Absolute Performance')\n",
    "\n",
    "# Normalized per task\n",
    "normalized = pivot_matrix.apply(lambda x: (x - x.min()) / (x.max() - x.min() + 1e-10), axis=0)\n",
    "sns.heatmap(normalized, annot=True, fmt='.2f', cmap='RdYlGn', ax=axes[1],\n",
    "            cbar_kws={'label': 'Normalized (0-1)'})\n",
    "axes[1].set_title('Normalized per Task (0=Worst, 1=Best)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/exp9_interaction_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Identify Universal vs Task-Specific Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy analysis\n",
    "strategy_stats = pd.DataFrame({\n",
    "    \"mean_across_tasks\": pivot_matrix.mean(axis=1),\n",
    "    \"std_across_tasks\": pivot_matrix.std(axis=1),\n",
    "    \"best_count\": (normalized == 1.0).sum(axis=1),\n",
    "    \"worst_count\": (normalized == 0.0).sum(axis=1)\n",
    "}).sort_values(\"mean_across_tasks\", ascending=False)\n",
    "\n",
    "print(\"=== Strategy Analysis ===\")\n",
    "print(\"\\nRanked by average performance:\")\n",
    "print(strategy_stats.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify universal strategies (low variance, good mean)\n",
    "print(\"\\n=== Universal vs Specialized ===\")\n",
    "\n",
    "mean_threshold = strategy_stats[\"mean_across_tasks\"].median()\n",
    "std_threshold = strategy_stats[\"std_across_tasks\"].median()\n",
    "\n",
    "print(\"\\nUniversal (good everywhere, low variance):\")\n",
    "universal = strategy_stats[\n",
    "    (strategy_stats[\"mean_across_tasks\"] > mean_threshold) &\n",
    "    (strategy_stats[\"std_across_tasks\"] < std_threshold)\n",
    "]\n",
    "for s in universal.index:\n",
    "    print(f\"  {s}\")\n",
    "\n",
    "print(\"\\nSpecialized (high variance):\")\n",
    "specialized = strategy_stats[strategy_stats[\"std_across_tasks\"] > std_threshold]\n",
    "for s in specialized.index:\n",
    "    best_task = pivot_matrix.loc[s].idxmax()\n",
    "    worst_task = pivot_matrix.loc[s].idxmin()\n",
    "    print(f\"  {s}: best on '{best_task}', worst on '{worst_task}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best strategy per task\n",
    "print(\"\\n=== Best Strategy per Task ===\")\n",
    "for task in TASKS.keys():\n",
    "    best_strategy = pivot_matrix[task].idxmax()\n",
    "    best_score = pivot_matrix[task].max()\n",
    "    print(f\"  {task:15s}: {best_strategy} (score={best_score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interaction Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for significant interactions (where strategy effect depends on task)\n",
    "# Compare to additive model: E[Y] = strategy_effect + task_effect\n",
    "\n",
    "strategy_means = pivot_matrix.mean(axis=1)\n",
    "task_means = pivot_matrix.mean(axis=0)\n",
    "grand_mean = pivot_matrix.values.mean()\n",
    "\n",
    "# Additive prediction\n",
    "additive_pred = pd.DataFrame(\n",
    "    [[strategy_means[s] + task_means[t] - grand_mean for t in TASKS.keys()] for s in STRATEGIES.keys()],\n",
    "    index=STRATEGIES.keys(),\n",
    "    columns=TASKS.keys()\n",
    ")\n",
    "\n",
    "# Residuals (interaction effects)\n",
    "residuals = pivot_matrix - additive_pred\n",
    "\n",
    "print(\"=== Interaction Effects (Residuals from Additive Model) ===\")\n",
    "print(\"Positive = strategy works better than expected for this task\")\n",
    "print(\"Negative = strategy works worse than expected for this task\\n\")\n",
    "print(residuals.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize interactions\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "sns.heatmap(residuals, annot=True, fmt='.2f', cmap='RdBu_r', center=0, ax=ax,\n",
    "            cbar_kws={'label': 'Interaction Effect'})\n",
    "ax.set_title('Strategy Ã— Task Interactions\\n(Deviation from Additive Model)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/exp9_interactions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT 9 SUMMARY: Prompt-Task Interaction Matrix\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Best Overall Strategies:\")\n",
    "for s in strategy_stats.head(3).index:\n",
    "    print(f\"   {s}: mean={strategy_stats.loc[s, 'mean_across_tasks']:.3f}\")\n",
    "\n",
    "print(\"\\n2. Task-Specific Findings:\")\n",
    "for task in TASKS.keys():\n",
    "    best = pivot_matrix[task].idxmax()\n",
    "    print(f\"   {task}: best with '{best}'\")\n",
    "\n",
    "print(\"\\n3. Strongest Interactions:\")\n",
    "flat_residuals = residuals.unstack().sort_values()\n",
    "print(\"   Worst mismatches:\")\n",
    "for (task, strategy), val in flat_residuals.head(3).items():\n",
    "    print(f\"     {strategy} on {task}: {val:+.3f}\")\n",
    "print(\"   Best synergies:\")\n",
    "for (task, strategy), val in flat_residuals.tail(3).items():\n",
    "    print(f\"     {strategy} on {task}: {val:+.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "save_data = {\n",
    "    \"performance_matrix\": pivot_matrix.to_dict(),\n",
    "    \"strategy_stats\": strategy_stats.to_dict(),\n",
    "    \"interactions\": residuals.to_dict()\n",
    "}\n",
    "\n",
    "with open('../results/exp9_matrix_results.json', 'w') as f:\n",
    "    json.dump(save_data, f, indent=2, default=float)\n",
    "\n",
    "print(\"Results saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
